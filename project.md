
# ğŸ§ª AI Object & Person Detection Benchmark

## ğŸ“˜ Overview
This project benchmarks real-world object and person detection across commercial and open-source AI models using structured prompts, consistent inputs, and rubric-based scoring. It includes two primary testsâ€”image-based card detection and video-based person re-identification.

---

## ğŸ“‹ Vendors/Solutions Compared

| Type          | Model(s)                         | Interface           |
|---------------|----------------------------------|---------------------|
| Commercial    | OpenAI GPT-4o Vision             | ChatGPT / API       |
|               | Google Gemini Pro Vision         | Web / API           |
|               | AWS Rekognition (Image + Video)  | Console / API       |
| Open Source   | YOLOv8 + GroundingDINO           | Python, CLI         |
|               | Segment Anything + BLIP-2        | Python, CLI         |

---

## ğŸ–¼ï¸ Test 1: Greeting Card Wall (Image)

### ğŸ¯ Goal
Evaluate each model's ability to:
- Detect section headers (e.g., â€œRomantic Birthdayâ€)
- Identify illustrations on cards (e.g., bear, dog, balloons)
- Parse text on card fronts (e.g., â€œHappy Birthdayâ€)

### ğŸ“¥ Input
- High-resolution image of a greeting card wall

### ğŸ’¬ Prompts
- â€œWhere are the â€˜Romantic Birthdayâ€™ cards?â€
- â€œShow me all cards with a bear on them.â€
- â€œWhich cards have the phrase â€˜Happy Birthdayâ€™ visible on the front?â€

### ğŸ“ˆ Scoring Rubric

| Metric                    | Description                                             | Score (0â€“5) |
|---------------------------|---------------------------------------------------------|-------------|
| Text-Region Localization  | Finds section headers like â€œRomantic Birthdayâ€          |             |
| Object-Level Detection    | Finds cards with requested illustrations                |             |
| OCR + Semantic Parsing    | Parses and understands visible text                     |             |
| Visual Bounding Clarity   | Bounding box accuracy and completeness                  |             |
| Instruction Following     | Follows the prompt and matches requested criteria       |             |

---

## ğŸ¥ Test 2: Person Re-Identification (Video)

### ğŸ¯ Goal
Assess the ability to visually track a person in video based on description.

### ğŸ“¥ Input
- 10â€“30 second video clip featuring multiple people, movement, and occlusion

### ğŸ’¬ Prompts
- â€œFind the person in the red hoodie and black pants.â€
- â€œShow me when [target] enters the frame and track them.â€

### ğŸ“ˆ Scoring Rubric

| Metric                    | Description                                               | Score (0â€“5) |
|---------------------------|-----------------------------------------------------------|-------------|
| Target Re-ID Accuracy     | Correctly identifies the person and tracks them           |             |
| Robustness to Occlusion   | Maintains ID despite partial obstruction                  |             |
| Temporal Awareness        | Recognizes entry/exit in the video timeline               |             |
| Visual Reasoning          | Explains or justifies selection (if supported)            |             |
| Instruction Following     | Matches the prompt with high fidelity                     |             |

---

## ğŸ“¤ Output Format

For each vendor and test:
- Screenshots or JSON of detected regions
- Written explanation or logs (if available)
- Completed rubric with 0â€“5 scores
- Optional: timing info for API-based solutions

---

## âœ… Project Checklist

### ğŸ“ Setup
- [ ] Collect and organize image and video test inputs
- [ ] Preprocess media as needed (format, resolution)
- [ ] Ensure all test data is reproducible and documented

### ğŸ”§ Tool Access
- [ ] OpenAI GPT-4o access via ChatGPT or API
- [ ] Gemini Pro Vision access (API or Bard)
- [ ] AWS Rekognition credentials (IAM + SDK)
- [ ] Python env for YOLOv8 + GroundingDINO
- [ ] Python env for Segment Anything + BLIP-2

### ğŸš€ Run Benchmarks
- [ ] Execute each model with consistent prompts
- [ ] Log all output (visual + text)
- [ ] Score based on rubric

### ğŸ§¾ Documentation
- [ ] Fill results table
- [ ] Add insights and reflections
- [ ] Publish results to GitHub/Notion
- [ ] Include in article writeup

---

## ğŸ”— References

- [YOLOv8 GitHub](https://github.com/ultralytics/ultralytics)
- [Grounding DINO](https://github.com/IDEA-Research/GroundingDINO)
- [Segment Anything](https://github.com/facebookresearch/segment-anything)
- [BLIP-2](https://github.com/salesforce/LAVIS)
- [AWS Rekognition Docs](https://docs.aws.amazon.com/rekognition/)
- [GPT-4o](https://openai.com/index/gpt-4o/)
- [Gemini](https://deepmind.google/technologies/gemini/)

---

*Created by David Proctor â€” July 2025*
